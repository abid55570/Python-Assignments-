{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba3aaadc-8042-40bc-a266-4259aae9a70b",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f27651-fe8f-4fcd-9819-b2e4880d8b19",
   "metadata": {},
   "source": [
    "Assumptions for using ANOVA (Analysis of Variance):\n",
    "\n",
    "Independence: The observations within each group are independent of each other. This means that the values in one group do not depend on or influence the values in another group.\n",
    "\n",
    "Normality: The residuals (the differences between the observed values and the predicted values) are normally distributed within each group. This assumption is important because ANOVA relies on the normal distribution for making inferences.\n",
    "\n",
    "Homogeneity of Variance: The variability of the residuals is equal across all groups. In other words, the variances of the groups being compared are approximately equal.\n",
    "\n",
    "Violations that could impact the validity of ANOVA results:\n",
    "\n",
    "Violation of independence: If the observations within groups are not independent, it can lead to biased and unreliable results. For example, if a study measures the same individuals repeatedly over time and their responses are correlated, the assumption of independence is violated.\n",
    "\n",
    "Violation of normality: If the residuals within each group are not normally distributed, the validity of ANOVA results may be compromised. This can happen when the data is highly skewed or has extreme outliers. Non-normality can lead to incorrect p-values and confidence intervals.\n",
    "\n",
    "Violation of homogeneity of variance: If the variability of the residuals differs significantly across groups, the assumptions of ANOVA are violated. This is known as heteroscedasticity. It can occur when the groups being compared have different variances or when there are outliers in some groups.\n",
    "\n",
    "When these assumptions are violated, alternative statistical tests or data transformations may be necessary to obtain valid results. For example, non-parametric tests like the Kruskal-Wallis test can be used when the assumption of normality is violated, or transformations such as logarithmic or square root transformations can be applied to achieve approximate normality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5c5d3-b00c-4087-8fb6-8f9ea90b5d1f",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421fe396-3638-45ba-b174-a19495ed071f",
   "metadata": {},
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "One-Way ANOVA: This type of ANOVA is used when there is a single categorical independent variable (also known as a factor) and a continuous dependent variable. It is used to compare means across two or more groups to determine if there are significant differences between them. For example, you might use a one-way ANOVA to compare the average test scores of students from different schools or to compare the effectiveness of different treatments on a medical condition.\n",
    "\n",
    "Two-Way ANOVA: This type of ANOVA is used when there are two categorical independent variables (factors) and a continuous dependent variable. It allows for the examination of the main effects of each factor as well as their interaction effect on the dependent variable. Two-way ANOVA is useful when you want to analyze the effects of two independent variables simultaneously. For instance, you might use a two-way ANOVA to examine the effects of both gender and age group on the performance of athletes.\n",
    "\n",
    "Factorial ANOVA: This type of ANOVA is an extension of the two-way ANOVA and is used when there are two or more categorical independent variables (factors) and a continuous dependent variable. It allows for the examination of main effects and interaction effects among multiple factors. Factorial ANOVA is employed when you want to explore the combined effects of multiple independent variables on the dependent variable. For example, you might use a factorial ANOVA to investigate the impact of both education level and income level on job satisfaction.\n",
    "\n",
    "These different types of ANOVA provide flexibility in analyzing data with varying numbers of independent variables, allowing researchers to examine the effects of different factors and their interactions on the outcome of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b4be2-c8ba-455b-b07f-8657096ba341",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff28ba0e-a1a9-41a2-83fc-c1a503d37051",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the division of the total variability in the data into different components or sources of variation. It involves decomposing the total sum of squares (SS) into smaller components that represent the variation explained by the factors being tested and the residual variation that is not explained.\n",
    "\n",
    "The partitioning of variance is important to understand in ANOVA for several reasons:\n",
    "\n",
    "Identifying sources of variation: By partitioning the total variance, ANOVA allows us to identify and quantify the sources of variation in the data. This helps in understanding the relative contributions of different factors or groups to the overall variability. For example, in a one-way ANOVA comparing test scores of students from different schools, the partitioning of variance can reveal how much of the total variability is due to school differences and how much is due to individual differences within schools.\n",
    "\n",
    "Assessing the significance of factors: ANOVA determines whether the observed differences among groups are statistically significant. The partitioning of variance provides the basis for calculating the F-statistic, which compares the variability between groups to the variability within groups. By comparing these two sources of variability, ANOVA determines if the differences among groups are larger than what would be expected by chance alone.\n",
    "\n",
    "Estimating effect sizes: ANOVA allows us to estimate the effect size of the factors being tested. The partitioning of variance provides information on the proportion of the total variability that can be attributed to each factor. This information helps in understanding the practical significance and magnitude of the differences observed between groups or conditions.\n",
    "\n",
    "Design optimization: Understanding the partitioning of variance can assist in experimental design and optimization. By identifying the factors that contribute most to the variability in the outcome variable, researchers can focus on controlling or manipulating those factors to achieve desired outcomes.\n",
    "\n",
    "Overall, the partitioning of variance in ANOVA provides insights into the sources of variation, helps assess the significance of factors, and allows for estimating effect sizes. It is a fundamental concept that facilitates the interpretation and understanding of ANOVA results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3837847-8ea5-40ad-af96-3208d9e9e30a",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3313dfb-763b-444b-8fe8-7f03d9255bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 93.33333333333334\n",
      "Explained Sum of Squares (SSE): 63.33333333333333\n",
      "Residual Sum of Squares (SSR): 30.000000000000014\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data for three groups\n",
    "group1 = np.array([5, 7, 9, 6, 8])\n",
    "group2 = np.array([4, 3, 6, 5, 7])\n",
    "group3 = np.array([10, 12, 9, 11, 8])\n",
    "\n",
    "# Combine the data from all groups\n",
    "data = np.concatenate((group1, group2, group3))\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = np.array([np.mean(group1), np.mean(group2), np.mean(group3)])\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = np.sum((group_means - overall_mean) ** 2) * len(group1)\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc7302-af55-46df-90cf-9bc0e81dbbde",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68617ad0-c455-408e-a608-70c0c0ee1219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Group1: 40.000000000000064\n",
      "Main Effect of Group2: 7.888609052210118e-31\n",
      "Interaction Effect: 7.888609052210118e-31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({'Group1': [1, 2, 3, 4, 5],\n",
    "                     'Group2': [6, 7, 8, 9, 10],\n",
    "                     'Response': [10, 12, 14, 16, 18]})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Response ~ Group1 + Group2 + Group1:Group2', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract the main effects and interaction effects\n",
    "main_effect_group1 = anova_table['sum_sq']['Group1']\n",
    "main_effect_group2 = anova_table['sum_sq']['Group2']\n",
    "interaction_effect = anova_table['sum_sq']['Group1:Group2']\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Group1:\", main_effect_group1)\n",
    "print(\"Main Effect of Group2:\", main_effect_group2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a243998-c176-4fc5-bbc4-98aff023246d",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57316c91-b703-4971-9bec-d97b8582abe5",
   "metadata": {},
   "source": [
    "In the given scenario, conducting a one-way ANOVA resulted in an F-statistic of 5.23 and a p-value of 0.02. Based on these results, we can draw the following conclusions:\n",
    "\n",
    "Differences between the groups: The obtained F-statistic of 5.23 indicates that there are significant differences between the groups being compared. This suggests that the means of the groups are not equal.\n",
    "\n",
    "Interpretation of results: The p-value of 0.02 indicates the probability of obtaining an F-statistic as extreme as 5.23, assuming that the null hypothesis is true (i.e., the group means are equal). Typically, a p-value below a pre-determined significance level (e.g., 0.05) is considered statistically significant. In this case, the p-value of 0.02 is less than 0.05, suggesting that we have sufficient evidence to reject the null hypothesis.\n",
    "\n",
    "Therefore, based on the obtained results, we can conclude that there are significant differences between the groups. However, it is important to note that the one-way ANOVA itself does not provide information about which specific groups differ from each other. To determine the specific group differences, post-hoc tests (e.g., Tukey's HSD, Bonferroni) or pairwise comparisons can be conducted.\n",
    "\n",
    "Additionally, the effect size of the group differences should also be considered for practical significance. The magnitude of the effect size can provide insights into the practical importance or meaningfulness of the observed differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d67d5-e8cf-467a-8e8c-e4923240adad",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c176a-7c6c-44e7-a8c3-0f9dd0329b35",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration, as the presence of missing data can affect the validity and reliability of the results. Here are some common methods for handling missing data in a repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "Complete Case Analysis (Listwise deletion): This approach involves excluding participants with missing data from the analysis. It can lead to a reduction in sample size and loss of statistical power. If missingness is related to the outcome or predictor variables, this method may introduce bias and produce inaccurate results.\n",
    "\n",
    "Pairwise Deletion (Available Case Analysis): This approach analyzes only the available data for each specific pairwise comparison. It utilizes all available data for each comparison, but it can lead to inconsistent group sizes across comparisons. The potential consequence is a loss of statistical power and biased estimates if the missingness is related to the outcome or predictor variables.\n",
    "\n",
    "Mean Substitution: This method replaces missing values with the mean value of the available data for that variable. It can artificially reduce the variability in the data and lead to underestimation of standard errors and inflated statistical significance. Mean substitution assumes that missing data are missing completely at random (MCAR), which is often unrealistic in practice.\n",
    "\n",
    "Last Observation Carried Forward (LOCF): LOCF replaces missing values with the last observed value for that variable. It assumes that the missing data would have remained constant over time. LOCF can introduce bias if the missingness is related to the pattern of change over time.\n",
    "\n",
    "Multiple Imputation: This method involves creating multiple imputed datasets where missing values are replaced with plausible values based on statistical models. The analysis is performed on each imputed dataset, and the results are combined to obtain overall estimates. Multiple imputation can yield less biased estimates and valid standard errors compared to other methods, assuming the imputation model is appropriate.\n",
    "\n",
    "The consequences of using different methods to handle missing data can vary. Biased estimates, incorrect standard errors, and inflated or underestimated statistical significance are some potential consequences. The choice of method should depend on the assumptions made about the missing data mechanism and the extent of missingness. Multiple imputation is generally considered a preferred method when the missingness is not completely random, as it provides a more robust and statistically valid approach. However, it is important to consult with experts or statisticians to choose the most appropriate method based on the specific characteristics of the data and the missing data mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762156b9-9d94-4ead-b0a8-35ae45866aab",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8afa368-d46a-4ed4-b9a4-efec5e33a14f",
   "metadata": {},
   "source": [
    "After conducting an ANOVA and finding a significant overall effect, post-hoc tests are often employed to determine which specific group differences are driving the significance. Here are some common post-hoc tests used after ANOVA and when they would be appropriate:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) Test: This test is used when comparing all possible pairs of group means. It controls the experiment-wise error rate, providing simultaneous confidence intervals for all pairwise comparisons. Tukey's HSD is appropriate when the primary goal is to determine which specific groups differ significantly from each other. For example, in a study comparing the effectiveness of four different treatments on pain reduction, Tukey's HSD can be used to identify which treatment groups significantly differ from each other.\n",
    "\n",
    "Bonferroni Correction: This is a conservative method that adjusts the significance level for multiple comparisons. It divides the desired significance level by the number of comparisons being made to maintain a family-wise error rate. Bonferroni correction is appropriate when conducting a large number of pairwise comparisons and controlling for the risk of type I error. However, it can result in decreased power due to the more stringent significance criterion.\n",
    "\n",
    "Scheffé's Test: Scheffé's test is a conservative and robust post-hoc test that can be used for any number of pairwise comparisons. It provides confidence intervals and controls for the family-wise error rate. Scheffé's test is suitable when the sample size is small or unequal, and when the assumption of equal variances is violated. It is a more conservative option compared to Tukey's HSD, making it useful in situations where preserving the overall type I error rate is crucial.\n",
    "\n",
    "Duncan's Multiple Range Test: This test is often used in situations where the number of treatments or groups is fixed and predetermined. It compares group means by calculating ranges and identifying significant differences. Duncan's test is more liberal than Tukey's HSD, but less conservative than Bonferroni correction. It can be used when there is prior knowledge about the specific groups to be compared.\n",
    "\n",
    "The choice of post-hoc test depends on various factors such as the specific research question, the number of pairwise comparisons, the sample size, and assumptions about the data. It is important to consider the properties and assumptions of each test and select the most appropriate one based on the study design and goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83668d8e-8028-4fe8-9a5c-3b23c00d228c",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b04cb3-b6ac-4f9e-b26d-c3ea6da1018b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 31.50561415317408\n",
      "p-value: 3.878303260340885e-12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "diet_A = np.array([2, 3, 4, 5, 2, 3, 4, 5, 3, 4, 5, 6, 3, 4, 5, 6, 4, 5, 6, 7,\n",
    "                   4, 5, 6, 7, 5, 6, 7, 8, 6, 7, 8, 9, 6, 7, 8, 9, 7, 8, 9, 10,\n",
    "                   7, 8, 9, 10, 8, 9, 10, 11, 9, 10, 11, 12])\n",
    "diet_B = np.array([3, 4, 5, 6, 7, 8, 5, 6, 7, 8, 9, 6, 7, 8, 9, 10, 7, 8, 9, 10,\n",
    "                   11, 8, 9, 10, 11, 12, 9, 10, 11, 12, 13, 10, 11, 12, 13, 14,\n",
    "                   11, 12, 13, 14, 15, 12, 13, 14, 15, 16, 13, 14, 15, 16, 17])\n",
    "diet_C = np.array([4, 5, 6, 7, 8, 9, 10, 6, 7, 8, 9, 10, 11, 7, 8, 9, 10, 11, 12,\n",
    "                   8, 9, 10, 11, 12, 13, 9, 10, 11, 12, 13, 14, 10, 11, 12, 13,\n",
    "                   14, 15, 11, 12, 13, 14, 15, 16, 12, 13, 14, 15, 16, 17])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e1a70-1cb8-4e9d-b5bd-cf3cd028efdb",
   "metadata": {},
   "source": [
    "If the p-value is below a pre-determined significance level (e.g., 0.05), we can conclude that there are significant differences between the mean weight loss of the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ed2be-8800-42f2-8907-78f5d949bf3a",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34ed37e9-ed7b-4c13-ad35-9682df451c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             df     sum_sq   mean_sq         F    PR(>F)\n",
      "C(Software)                 2.0   1.400000  0.700000  0.600000  0.556837\n",
      "C(Experience)               1.0   0.033333  0.033333  0.028571  0.867189\n",
      "C(Software):C(Experience)   2.0   2.866667  1.433333  1.228571  0.310470\n",
      "Residual                   24.0  28.000000  1.166667       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'] * 2,\n",
    "    'Experience': ['Novice', 'Experienced'] * 15,\n",
    "    'Time': [10, 12, 11, 9, 10, 11, 11, 10, 9, 12, 11, 10, 10, 9, 8, 11, 10, 9, 10, 11, 12, 11, 10, 9, 10, 11, 12, 11, 10, 9]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a8a9e-b6c3-43ea-b712-4921f3cb720c",
   "metadata": {},
   "source": [
    "Interpreting the results:\n",
    "\n",
    "If the p-value for the main effect of software is below a pre-determined significance level (e.g., 0.05), it indicates a significant difference in the average time taken to complete the task between the software programs.\n",
    "If the p-value for the main effect of experience is below the significance level, it suggests a significant difference in the average time taken to complete the task between novice and experienced employees.\n",
    "If the p-value for the interaction effect is below the significance level, it indicates that the effect of software programs on the time taken to complete the task depends on the experience level of the employees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3001f96-f91f-43f7-b6d3-cf81f4457fa7",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cc760aa-ae26-4830-b28f-c09827fdc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test\n",
      "t-statistic:  -5.942746276756954\n",
      "p-value:  6.821375488929941e-07\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data\n",
    "control_group = [78, 82, 85, 73, 80, 79, 81, 77, 76, 84, 83, 79, 81, 78, 80, 76, 82, 79, 77, 75]\n",
    "experimental_group = [82, 88, 90, 79, 86, 87, 89, 84, 83, 88, 86, 83, 87, 84, 86, 82, 88, 85, 83, 80]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the results\n",
    "print(\"Two-Sample T-Test\")\n",
    "print(\"t-statistic: \", t_statistic)\n",
    "print(\"p-value: \", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797ae47-a2f4-4457-a73e-3daeaf976f8e",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f290dcd-3e83-492b-83ed-f5eeeb942629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Measures ANOVA:\n",
      "F-statistic: 0.7352457942323778\n",
      "p-value: 0.48909127714548284\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'Store': ['A', 'B', 'C'] * 10,\n",
    "    'Day': list(range(1, 11)) * 3,\n",
    "    'Sales': [100, 95, 110, 105, 98, 105, 102, 99, 101, 96, 99, 100, 105, 108, 103, 98, 101, np.nan, 102, 106, 100, 103, 105, 107, 102, 99, 98, 104, 100, 103]\n",
    "})\n",
    "\n",
    "# Drop rows with missing values (NaNs)\n",
    "data = data.dropna()\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "anova_result = data.groupby('Store')['Sales'].apply(list).apply(np.array).apply(list).to_list()\n",
    "f_statistic, p_value = f_oneway(*anova_result)\n",
    "\n",
    "# Print the ANOVA results\n",
    "print(\"Repeated Measures ANOVA:\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8a416-0ed2-4e60-b00b-71d9de5bd48c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
